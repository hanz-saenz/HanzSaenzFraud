# -*- coding: utf-8 -*-
"""Detección de fraude.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zRFSp67SyNalavPIvJbPanY-IVMcMwNL

## 1. Carga de Bibliotecas
"""

import pandas as pd
import joblib
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score

"""## 2. Cargar datos de entrenamiento y combinarlos, Preprocesamiento de Datos


"""

# Cargar los datos de entrenamiento
train_pacientes_aprobados = pd.read_csv('data/train/train_pacientes_aprobados.csv')
train_pacientes_rechazados = pd.read_csv('data/train/train_pacientes_rechazados.csv')
train_beneficiario = pd.read_csv('data/train/train_beneficiario.csv')
train_labels_aprovisionadores = pd.read_csv('data/train/train_labels_aprovisionadores.csv')


# Combinar los datasets de pacientes y beneficiarios
train_data = pd.concat([train_pacientes_aprobados, train_pacientes_rechazados], ignore_index=True)
train_data = train_data.merge(train_beneficiario, on='cod_beneficiario', how='left')

# Añadir etiquetas de fraude (0: no fraude, 1: fraude)
train_data = train_data.merge(train_labels_aprovisionadores, on='aprovisionador', how='left')
train_data.to_csv('train_data.csv', index=False)
# Verificar si hay valores nulos y tratarlos adecuadamente.
train_data = pd.read_csv('train_data.csv')
train_data.fillna(0, inplace=True)

"""## 2.1. Codificación de Variables Categóricas

Necesitamos convertir las variables categóricas en un formato que los algoritmos de machine learning puedan utilizar. Utilizaremos **LabelEncoder** para esto
"""

# Identificar columnas categóricas
categorical_columns = train_data.select_dtypes(include=['object']).columns

# Codificar variables categóricas en train_data
label_encoders = {}
for col in categorical_columns:
    le = LabelEncoder()
    train_data[col] = le.fit_transform(train_data[col].astype(str))
    label_encoders[col] = le

"""## 2.2. Selección de Características y Variable Objetivo

Separaremos las características (**X**) y la variable objetivo (**y**) del conjunto de entrenamiento
"""

# Separar características y variable objetivo
X = train_data.drop(columns=['es_fraudulento'])

y = train_data['es_fraudulento']

"""## 3. Entrenamiento del Modelo

### 3.1. División de los Datos

Dividiremos los datos de entrenamiento en conjuntos de entrenamiento y validación.
"""

# Dividir los datos en entrenamiento y validación
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)

"""### 3.2. Entrenamiento con Random Forest

Utilizaremos un **RandomForestClassifier** debido a su capacidad para manejar datos desequilibrados y su robustez.
"""

# Entrenar el modelo
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

"""## 4. Evaluación del Modelo

Evaluamos el modelo utilizando los datos de validación.
"""

# Realizar predicciones en el conjunto de validación
y_pred = model.predict(X_val)

# Guardar el modelo
joblib.dump(model, 'fraud_detection_model.pkl')
# Evaluar el modelo
print(classification_report(y_val, y_pred))
print(f'Accuracy: {accuracy_score(y_val, y_pred)}')

from sklearn.metrics import roc_auc_score
auc = roc_auc_score(y_val, y_pred)
print(f'AUC: {auc}')

"""## 5. Predicción en el Conjunto de Test

### 5.1. Cargar datos de Prueba
"""

# Cargar los datos de pruebas
test_pacientes_aprobados = pd.read_csv('data/test/test_pacientes_aprobados.csv')
test_pacientes_rechazados = pd.read_csv('data/test/test_pacientes_rechazados.csv')
test_beneficiario = pd.read_csv('data/test/test_beneficiario.csv')
test_labels_aprovisionadores = pd.read_csv('data/test/test_labels_aprovisionadores.csv', sep=';')

# Combinar los datos de prueba
test_data = pd.concat([test_pacientes_aprobados, test_pacientes_rechazados], ignore_index=True)
test_data = test_data.merge(test_beneficiario, on='cod_beneficiario', how='left')
test_data = test_data.merge(test_labels_aprovisionadores, on='aprovisionador', how='left')
# Verificar si hay valores nulos y tratarlos adecuadamente.
test_data.to_csv('test_data.csv', index=False)
test_data.fillna(0, inplace=True)

# Aplicar el mismo codificador en test_data
label_encoder = {}
for col in categorical_columns:
    le = LabelEncoder()
    test_data[col] = le.fit_transform(test_data[col].astype(str))
    label_encoder[col] = le

# Eliminar la columna del conjunto de pruebas

test_data = test_data.drop('es_fraudulento', axis=1)

"""### 5.2. Realizar Predicciones

Utilizamos el modelo entrenado para predecir si hay fraude en los datos de test.
"""

# Realizar predicciones en test_data
test_data_predictions = model.predict(test_data)

# Convertir las predicciones a 'Yes' o 'No'
test_data['es_fraudulento'] = test_data_predictions
test_data['es_fraudulento'] = test_data['es_fraudulento'].map({1: 'Yes', 0: 'No'})

"""## 6. Guardar Datos

Guardamos los resultados en un nuevo archivo CSV.
"""

test_data['aprovisionador'] = label_encoders['aprovisionador'].inverse_transform(test_data['aprovisionador'])
test_data['cod_beneficiario'] = label_encoders['cod_beneficiario'].inverse_transform(test_data['cod_beneficiario'])

# Guardar los resultados en un nuevo archivo CSV
test_data.to_csv('test_data_with_predictions.csv', index=False)
resultado_final = test_data[['aprovisionador', 'es_fraudulento']].copy()

# Guardar el DataFrame en un archivo CSV
resultado_final.to_csv('train_beneficiario.csv', index=False)
